{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé≠ SadTalker Gradio UI for Google Colab\n",
    "\n",
    "This notebook creates a Gradio interface for generating talking avatar videos with real-time progress updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Clone SadTalker Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/OpenTalker/SadTalker.git\n",
    "%cd SadTalker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install gradio moviepy pydub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash scripts/download_models.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "BASE_DIR = \"/content/SadTalker\"\n",
    "RESULT_DIR = f\"{BASE_DIR}/results\"\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "# Global variables\n",
    "current_process = None\n",
    "process_start_time = None\n",
    "\n",
    "\n",
    "def run_inference_streaming(image_path, audio_path, progress=gr.Progress()):\n",
    "    \"\"\"Run SadTalker inference with real-time log streaming\"\"\"\n",
    "    global current_process, process_start_time\n",
    "    \n",
    "    if image_path is None or audio_path is None:\n",
    "        return \"‚ùå Please upload both image and audio files\", \"\", None, None\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        return \"‚ùå Image file not found\", \"\", None, None\n",
    "    if not os.path.exists(audio_path):\n",
    "        return \"‚ùå Audio file not found\", \"\", None, None\n",
    "    \n",
    "    process_start_time = time.time()\n",
    "    start_time_str = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    \n",
    "    cmd = [\n",
    "        \"python\", \"inference.py\",\n",
    "        \"--driven_audio\", audio_path,\n",
    "        \"--source_image\", image_path,\n",
    "        \"--result_dir\", RESULT_DIR,\n",
    "        \"--enhancer\", \"gfpgan\",\n",
    "        \"--still\",\n",
    "        \"--preprocess\", \"full\"\n",
    "    ]\n",
    "    \n",
    "    logs = []\n",
    "    status_msg = f\"‚è≥ Started at {start_time_str}\\n\"\n",
    "    \n",
    "    try:\n",
    "        process = subprocess.Popen(\n",
    "            cmd,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            universal_newlines=True,\n",
    "            bufsize=1\n",
    "        )\n",
    "        current_process = process\n",
    "        \n",
    "        # Stream output in real-time\n",
    "        for line in iter(process.stdout.readline, ''):\n",
    "            if line:\n",
    "                line = line.strip()\n",
    "                logs.append(line)\n",
    "                elapsed = time.time() - process_start_time\n",
    "                \n",
    "                if progress is not None:\n",
    "                    progress(0, desc=f\"Processing... {line[:60]}\")\n",
    "                \n",
    "                yield (\n",
    "                    f\"‚è≥ Processing... ({len(logs)} lines logged) | Elapsed: {elapsed:.1f}s\",\n",
    "                    \"\\n\".join(logs[-25:]),\n",
    "                    None,\n",
    "                    f\"{elapsed:.2f} seconds\"\n",
    "                )\n",
    "        \n",
    "        process.wait()\n",
    "        \n",
    "        elapsed = time.time() - process_start_time\n",
    "        elapsed_str = f\"{elapsed:.2f} seconds ({elapsed/60:.2f} minutes)\"\n",
    "        \n",
    "        # Find latest video\n",
    "        output_video = None\n",
    "        videos = sorted(Path(RESULT_DIR).rglob(\"*.mp4\"), key=os.path.getmtime, reverse=True)\n",
    "        if videos:\n",
    "            output_video = str(videos[0])\n",
    "            status_msg = f\"‚úÖ Generation completed!\\n‚è±Ô∏è Time taken: {elapsed_str}\\nüìπ Output: {os.path.basename(output_video)}\"\n",
    "        else:\n",
    "            status_msg = f\"‚ö†Ô∏è Process completed but no video found in {RESULT_DIR}\"\n",
    "        \n",
    "        yield (\n",
    "            status_msg,\n",
    "            \"\\n\".join(logs[-35:]),\n",
    "            output_video,\n",
    "            elapsed_str\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"‚ùå Error occurred: {str(e)}\"\n",
    "        yield (\n",
    "            error_msg,\n",
    "            \"\\n\".join(logs) + f\"\\n\\nERROR: {str(e)}\",\n",
    "            None,\n",
    "            None\n",
    "        )\n",
    "    finally:\n",
    "        current_process = None\n",
    "\n",
    "\n",
    "def generate_video(image, audio, progress=gr.Progress()):\n",
    "    \"\"\"Main function called by Gradio\"\"\"\n",
    "    if image is None or audio is None:\n",
    "        return \"‚ùå Please upload both image and audio files\", \"\", None, None\n",
    "    \n",
    "    image_path = image if isinstance(image, str) else image.name if hasattr(image, 'name') else image\n",
    "    audio_path = audio if isinstance(audio, str) else audio if isinstance(audio, dict) else None\n",
    "    \n",
    "    if isinstance(audio_path, dict):\n",
    "        audio_path = audio_path.get('name', audio_path.get('path', None))\n",
    "    \n",
    "    if not image_path or not audio_path:\n",
    "        return \"‚ùå Invalid file paths\", \"\", None, None\n",
    "    \n",
    "    for status, logs, video, elapsed in run_inference_streaming(image_path, audio_path, progress):\n",
    "        yield status, logs, video, elapsed\n",
    "\n",
    "\n",
    "def cancel_generation():\n",
    "    \"\"\"Cancel the current generation process\"\"\"\n",
    "    global current_process\n",
    "    if current_process:\n",
    "        current_process.terminate()\n",
    "        current_process = None\n",
    "        return \"üõë Generation cancelled\"\n",
    "    return \"‚ÑπÔ∏è No process running\"\n",
    "\n",
    "\n",
    "# Create Gradio Interface\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üé≠ SadTalker Avatar Generator (Colab)\n",
    "    \n",
    "    Upload **one face image** and **one audio file** to generate a talking avatar video.\n",
    "    \n",
    "    **Features:**\n",
    "    - ‚úÖ Real-time generation progress\n",
    "    - ‚úÖ Live log streaming\n",
    "    - ‚úÖ Automatic video output display\n",
    "    - ‚úÖ Time tracking\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            image = gr.Image(\n",
    "                type=\"filepath\",\n",
    "                label=\"üì∑ Upload Face Image\",\n",
    "                height=300\n",
    "            )\n",
    "            audio = gr.Audio(\n",
    "                type=\"filepath\",\n",
    "                label=\"üéµ Upload Audio File\",\n",
    "                sources=[\"upload\", \"microphone\"]\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                run_btn = gr.Button(\n",
    "                    \"üöÄ Generate Avatar Video\",\n",
    "                    variant=\"primary\",\n",
    "                    size=\"lg\"\n",
    "                )\n",
    "                cancel_btn = gr.Button(\n",
    "                    \"üõë Cancel\",\n",
    "                    variant=\"stop\",\n",
    "                    size=\"lg\"\n",
    "                )\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            status = gr.Textbox(\n",
    "                label=\"üìä Status\",\n",
    "                value=\"Ready to generate...\",\n",
    "                interactive=False\n",
    "            )\n",
    "            \n",
    "            elapsed_time = gr.Textbox(\n",
    "                label=\"‚è±Ô∏è Elapsed Time\",\n",
    "                value=\"\",\n",
    "                interactive=False\n",
    "            )\n",
    "    \n",
    "    with gr.Row():\n",
    "        logs = gr.Textbox(\n",
    "            label=\"üìù Generation Logs (Real-time)\",\n",
    "            lines=15,\n",
    "            max_lines=30,\n",
    "            interactive=False,\n",
    "            show_copy_button=True\n",
    "        )\n",
    "    \n",
    "    with gr.Row():\n",
    "        video = gr.Video(\n",
    "            label=\"üé¨ Final Output Video\",\n",
    "            height=400\n",
    "        )\n",
    "    \n",
    "    # Event handlers\n",
    "    run_btn.click(\n",
    "        fn=generate_video,\n",
    "        inputs=[image, audio],\n",
    "        outputs=[status, logs, video, elapsed_time],\n",
    "        show_progress=\"full\"\n",
    "    )\n",
    "    \n",
    "    cancel_btn.click(\n",
    "        fn=cancel_generation,\n",
    "        outputs=[status]\n",
    "    )\n",
    "    \n",
    "    gr.Markdown(\"### üí° Tips:\")\n",
    "    gr.Markdown(\"\"\"\n",
    "    - Use a clear face image (front-facing works best)\n",
    "    - Audio should be clear and not too long for faster processing\n",
    "    - First generation may take longer due to model loading\n",
    "    - Check the logs for detailed progress information\n",
    "    \"\"\")\n",
    "\n",
    "# Launch the interface\n",
    "demo.launch(\n",
    "    debug=True,\n",
    "    share=True,\n",
    "    server_name=\"0.0.0.0\",\n",
    "    server_port=7860\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
