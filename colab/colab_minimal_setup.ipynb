{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé≠ SadTalker: Minimal Setup (No Full Clone)\n",
        "\n",
        "**Uses Colab's pre-installed PyTorch.** Downloads only essential code + models. No full repo clone.\n",
        "\n",
        "1. Upload **face image** and **audio** (base sound)\n",
        "2. Click **Generate** ‚Üí talking video with lip sync\n",
        "3. Gradio UI for easy interaction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Enable GPU\n",
        "\n",
        "**Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use Colab's pre-installed CUDA-enabled PyTorch (no need to reinstall)\n",
        "# Only install packages Colab may not have or that SadTalker needs\n",
        "# Note: face-alignment (hyphen) installs but imports as face_alignment (underscore)\n",
        "!pip install -q edge-tts face-alignment imageio imageio-ffmpeg librosa resampy pydub kornia yacs scikit-image basicsr facexlib gfpgan av safetensors gradio\n",
        "!apt-get update -qq && apt-get install -y -qq ffmpeg 2>/dev/null || true\n",
        "\n",
        "# Verify CUDA is available (Colab's PyTorch should already have it)\n",
        "import torch\n",
        "print(f\"‚úì PyTorch {torch.__version__}\")\n",
        "print(f\"‚úì CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úì CUDA device: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Download only essential code (src/ + inference.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import urllib.request\n",
        "import shutil\n",
        "\n",
        "BASE_DIR = \"/content/SadTalker\"\n",
        "TEMP_DIR = \"/tmp/sadtalker_extract\"\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n",
        "os.makedirs(TEMP_DIR, exist_ok=True)\n",
        "os.chdir(BASE_DIR)\n",
        "\n",
        "# Download repo as zip\n",
        "repo_url = \"https://github.com/OpenTalker/SadTalker/archive/refs/heads/main.zip\"\n",
        "zip_path = \"/tmp/sadtalker.zip\"\n",
        "print(\"Downloading SadTalker repository...\")\n",
        "urllib.request.urlretrieve(repo_url, zip_path)\n",
        "\n",
        "# Extract entire zip to temp directory\n",
        "print(\"Extracting essential files...\")\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(TEMP_DIR)\n",
        "\n",
        "# Move only src/ and inference.py to BASE_DIR\n",
        "extracted_root = os.path.join(TEMP_DIR, \"SadTalker-main\")\n",
        "if os.path.exists(extracted_root):\n",
        "    # Move src/ directory\n",
        "    src_src = os.path.join(extracted_root, \"src\")\n",
        "    src_dst = os.path.join(BASE_DIR, \"src\")\n",
        "    if os.path.exists(src_src):\n",
        "        if os.path.exists(src_dst):\n",
        "            shutil.rmtree(src_dst)\n",
        "        shutil.move(src_src, src_dst)\n",
        "        print(\"‚úì Moved src/ directory\")\n",
        "    \n",
        "    # Move inference.py\n",
        "    inf_src = os.path.join(extracted_root, \"inference.py\")\n",
        "    inf_dst = os.path.join(BASE_DIR, \"inference.py\")\n",
        "    if os.path.exists(inf_src):\n",
        "        if os.path.exists(inf_dst):\n",
        "            os.remove(inf_dst)\n",
        "        shutil.move(inf_src, inf_dst)\n",
        "        print(\"‚úì Moved inference.py\")\n",
        "\n",
        "# Cleanup\n",
        "shutil.rmtree(TEMP_DIR, ignore_errors=True)\n",
        "os.remove(zip_path)\n",
        "\n",
        "# Fix numpy compatibility issue (VisibleDeprecationWarning removed in newer numpy)\n",
        "preprocess_file = os.path.join(BASE_DIR, \"src\", \"face3d\", \"util\", \"preprocess.py\")\n",
        "if os.path.exists(preprocess_file):\n",
        "    with open(preprocess_file, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "    \n",
        "    # Find and fix the problematic line\n",
        "    fixed = False\n",
        "    for i, line in enumerate(lines):\n",
        "        if \"np.VisibleDeprecationWarning\" in line:\n",
        "            # Check if already fixed\n",
        "            if i > 0 and \"try:\" in lines[i-1]:\n",
        "                continue\n",
        "            \n",
        "            # Get indentation\n",
        "            indent = len(line) - len(line.lstrip())\n",
        "            indent_str = \" \" * indent\n",
        "            \n",
        "            # Replace single line with try/except block\n",
        "            lines[i] = f\"{indent_str}try:\\n{indent_str}    warnings.filterwarnings(\\\"ignore\\\", category=np.VisibleDeprecationWarning)\\n{indent_str}except AttributeError:\\n{indent_str}    pass  # VisibleDeprecationWarning removed in newer numpy\\n\"\n",
        "            fixed = True\n",
        "            break\n",
        "    \n",
        "    if fixed:\n",
        "        with open(preprocess_file, \"w\") as f:\n",
        "            f.writelines(lines)\n",
        "        print(\"‚úì Fixed numpy VisibleDeprecationWarning issue\")\n",
        "\n",
        "# Fix np.float in my_awing_arch.py\n",
        "awing_file = os.path.join(BASE_DIR, \"src\", \"face3d\", \"util\", \"my_awing_arch.py\")\n",
        "if os.path.exists(awing_file):\n",
        "    with open(awing_file, \"r\") as f:\n",
        "        content = f.read()\n",
        "    if \"np.float\" in content and \"np.float64\" not in content.split(\"np.float\")[0][-20:]:\n",
        "        import re\n",
        "        content = re.sub(r'\\bnp\\.float\\b', 'np.float64', content)\n",
        "        with open(awing_file, \"w\") as f:\n",
        "            f.write(content)\n",
        "        print(\"‚úì Fixed np.float ‚Üí np.float64 in my_awing_arch.py\")\n",
        "\n",
        "print(f\"\\n‚úì Essential code extracted to {BASE_DIR}\")\n",
        "print(f\"‚úì Found src/ directory: {os.path.exists(os.path.join(BASE_DIR, 'src'))}\")\n",
        "print(f\"‚úì Found inference.py: {os.path.exists(os.path.join(BASE_DIR, 'inference.py'))}\")\n",
        "\n",
        "# Fix face detection: Add face-alignment fallback to croper.py\n",
        "croper_file = os.path.join(BASE_DIR, \"src\", \"utils\", \"croper.py\")\n",
        "if os.path.exists(croper_file):\n",
        "    with open(croper_file, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "    \n",
        "    # Check if already patched\n",
        "    content_str = ''.join(lines)\n",
        "    if \"_get_face_alignment\" not in content_str:\n",
        "        # Find insertion point: after imports, before class Preprocesser\n",
        "        insert_idx = None\n",
        "        for i, line in enumerate(lines):\n",
        "            if \"class Preprocesser:\" in line:\n",
        "                insert_idx = i\n",
        "                break\n",
        "        \n",
        "        if insert_idx is not None:\n",
        "            # Insert face-alignment helper functions\n",
        "            patch_code = \"\"\"# Optional: 1adrianb/face-alignment returns 68 points directly (no 98->68 conversion)\n",
        "_FACE_ALIGNMENT = None\n",
        "\n",
        "def _get_face_alignment(device='cuda'):\n",
        "    \\\"\\\"\\\"Lazy-init face_alignment.FaceAlignment (68 landmarks, TWO_D).\\\"\\\"\\\"\n",
        "    global _FACE_ALIGNMENT\n",
        "    if _FACE_ALIGNMENT is None:\n",
        "        try:\n",
        "            import face_alignment\n",
        "            LandmarksType = face_alignment.LandmarksType\n",
        "            # TWO_D or _2D depending on package version\n",
        "            lm_type = getattr(LandmarksType, 'TWO_D', getattr(LandmarksType, '_2D', 1))\n",
        "            fa_device = 'cpu' if device == 'cpu' else 'cuda'\n",
        "            _FACE_ALIGNMENT = face_alignment.FaceAlignment(\n",
        "                lm_type, device=fa_device, face_detector='sfd'\n",
        "            )\n",
        "        except Exception:\n",
        "            _FACE_ALIGNMENT = False\n",
        "    return _FACE_ALIGNMENT if _FACE_ALIGNMENT is not None and _FACE_ALIGNMENT is not False else None\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "            lines.insert(insert_idx, patch_code)\n",
        "            \n",
        "            # Add device to __init__\n",
        "            for i, line in enumerate(lines):\n",
        "                if \"def __init__(self, device='cuda'):\" in line:\n",
        "                    # Find next line with self.predictor\n",
        "                    for j in range(i+1, min(i+5, len(lines))):\n",
        "                        if \"self.predictor = KeypointExtractor\" in lines[j]:\n",
        "                            # Check if device already added\n",
        "                            if \"self.device = device\" not in ''.join(lines[i:j+3]):\n",
        "                                lines.insert(j+1, \"        self.device = device\\n\")\n",
        "                            break\n",
        "                    break\n",
        "            \n",
        "            # Add fallback method before get_landmark\n",
        "            fallback_method = \"\"\"    def _get_landmark_face_alignment(self, img_np, det):\n",
        "        \\\"\\\"\\\"Fallback: use 1adrianb/face-alignment to get 68 landmarks on crop (no 98->68).\\\"\\\"\\\"\n",
        "        fa = _get_face_alignment(self.device)\n",
        "        if fa is None:\n",
        "            return None\n",
        "        try:\n",
        "            img = img_np[int(det[1]):int(det[3]), int(det[0]):int(det[2]), :]\n",
        "            if img.size == 0 or img.shape[0] == 0 or img.shape[1] == 0:\n",
        "                return None\n",
        "            # face_alignment expects RGB; get_landmarks returns list of (68, 2) or (68, 3)\n",
        "            preds = fa.get_landmarks(img)\n",
        "            if not preds or len(preds) == 0:\n",
        "                return None\n",
        "            lm = np.array(preds[0], dtype=np.float64)\n",
        "            if lm.ndim == 2 and lm.shape[0] == 68:\n",
        "                lm = lm[:, :2]\n",
        "            else:\n",
        "                return None\n",
        "            lm[:, 0] += int(det[0])\n",
        "            lm[:, 1] += int(det[1])\n",
        "            return lm\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "\"\"\"\n",
        "            \n",
        "            # Find get_landmark method and insert fallback before it\n",
        "            for i, line in enumerate(lines):\n",
        "                if \"    def get_landmark(self, img_np):\" in line:\n",
        "                    if \"_get_landmark_face_alignment\" not in ''.join(lines[max(0,i-10):i]):\n",
        "                        lines.insert(i, fallback_method)\n",
        "                    break\n",
        "            \n",
        "            # Modify get_landmark to add fallback at the end (before final except)\n",
        "            in_get_landmark = False\n",
        "            for i in range(len(lines)):\n",
        "                if \"    def get_landmark(self, img_np):\" in lines[i]:\n",
        "                    in_get_landmark = True\n",
        "                elif in_get_landmark and lines[i].strip().startswith(\"def \") and \"get_landmark\" not in lines[i]:\n",
        "                    # End of get_landmark method\n",
        "                    break\n",
        "                elif in_get_landmark and \"except Exception:\" in lines[i] and \"# Fallback: face_alignment\" not in ''.join(lines[max(0,i-3):i+1]):\n",
        "                    # Insert fallback before this except\n",
        "                    fallback_call = \"            # Fallback: face_alignment (68 landmarks directly)\\n            lm = self._get_landmark_face_alignment(img_np, det)\\n            return lm\\n\\n\"\n",
        "                    lines.insert(i, fallback_call)\n",
        "                    break\n",
        "            \n",
        "            with open(croper_file, \"w\") as f:\n",
        "                f.writelines(lines)\n",
        "            print(\"‚úì Added face-alignment fallback to croper.py\")\n",
        "        else:\n",
        "            print(\"‚ö† Could not find Preprocesser class in croper.py\")\n",
        "    else:\n",
        "        print(\"‚úì croper.py already patched with face-alignment fallback\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3.5: Fix numpy compatibility (if Step 3 had issues)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DIRECT FIX for IndentationError - run this cell\n",
        "import os\n",
        "preprocess_file = \"/content/SadTalker/src/face3d/util/preprocess.py\"\n",
        "\n",
        "if os.path.exists(preprocess_file):\n",
        "    with open(preprocess_file, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "    \n",
        "    # Find the problematic area (around line 12-13)\n",
        "    new_lines = []\n",
        "    i = 0\n",
        "    while i < len(lines):\n",
        "        line = lines[i]\n",
        "        \n",
        "        # If we see a standalone \"try:\" followed by warnings line without proper indent\n",
        "        if \"try:\" in line and i+1 < len(lines):\n",
        "            next_line = lines[i+1]\n",
        "            if \"np.VisibleDeprecationWarning\" in next_line:\n",
        "                try_indent = len(line) - len(line.lstrip())\n",
        "                warn_indent = len(next_line) - len(next_line.lstrip())\n",
        "                \n",
        "                # If warnings line is NOT properly indented (should be +4 spaces)\n",
        "                if warn_indent <= try_indent:\n",
        "                    # Remove the broken \"try:\" line, keep warnings line\n",
        "                    indent = warn_indent\n",
        "                    # Replace with proper try/except block\n",
        "                    new_lines.append(\" \" * indent + \"try:\\n\")\n",
        "                    new_lines.append(\" \" * indent + \"    warnings.filterwarnings(\\\"ignore\\\", category=np.VisibleDeprecationWarning)\\n\")\n",
        "                    new_lines.append(\" \" * indent + \"except AttributeError:\\n\")\n",
        "                    new_lines.append(\" \" * indent + \"    pass  # VisibleDeprecationWarning removed in newer numpy\\n\")\n",
        "                    i += 2  # Skip both try: and warnings line\n",
        "                    continue\n",
        "        \n",
        "        # If we see warnings line without try/except wrapper\n",
        "        if \"np.VisibleDeprecationWarning\" in line and i > 0:\n",
        "            prev_line = lines[i-1]\n",
        "            if \"try:\" not in prev_line:\n",
        "                indent = len(line) - len(line.lstrip())\n",
        "                # Insert try/except before this line\n",
        "                new_lines.append(\" \" * indent + \"try:\\n\")\n",
        "                new_lines.append(\" \" * indent + \"    warnings.filterwarnings(\\\"ignore\\\", category=np.VisibleDeprecationWarning)\\n\")\n",
        "                new_lines.append(\" \" * indent + \"except AttributeError:\\n\")\n",
        "                new_lines.append(\" \" * indent + \"    pass  # VisibleDeprecationWarning removed in newer numpy\\n\")\n",
        "                i += 1\n",
        "                continue\n",
        "        \n",
        "        new_lines.append(line)\n",
        "        i += 1\n",
        "    \n",
        "    # Write fixed content\n",
        "    with open(preprocess_file, \"w\") as f:\n",
        "        f.writelines(new_lines)\n",
        "    \n",
        "    print(\"‚úì Fixed preprocess.py! Now fixing my_awing_arch.py...\")\n",
        "else:\n",
        "    print(\"‚ö† preprocess.py not found. Run Step 3 first.\")\n",
        "\n",
        "# Also fix np.float in my_awing_arch.py\n",
        "awing_file = \"/content/SadTalker/src/face3d/util/my_awing_arch.py\"\n",
        "if os.path.exists(awing_file):\n",
        "    with open(awing_file, \"r\") as f:\n",
        "        content = f.read()\n",
        "    if \"np.float\" in content:\n",
        "        import re\n",
        "        content = re.sub(r'\\bnp\\.float\\b', 'np.float64', content)\n",
        "        with open(awing_file, \"w\") as f:\n",
        "            f.write(content)\n",
        "        print(\"‚úì Fixed np.float ‚Üí np.float64 in my_awing_arch.py\")\n",
        "    else:\n",
        "        print(\"‚úì my_awing_arch.py already fixed\")\n",
        "else:\n",
        "    print(\"‚ö† my_awing_arch.py not found\")\n",
        "\n",
        "print(\"\\n‚úì All fixes applied! Re-run Step 5 (Gradio UI) now.\")\n",
        "\n",
        "# Also fix torchvision compatibility issue\n",
        "print(\"\\nFixing torchvision compatibility...\")\n",
        "try:\n",
        "    import torchvision.transforms as transforms_module\n",
        "    if not hasattr(transforms_module, 'functional_tensor'):\n",
        "        # In newer torchvision, functional_tensor was moved/renamed\n",
        "        try:\n",
        "            from torchvision.transforms import functional as functional_tensor\n",
        "            transforms_module.functional_tensor = functional_tensor\n",
        "            print(\"‚úì Fixed torchvision compatibility\")\n",
        "        except ImportError:\n",
        "            # Create a minimal shim\n",
        "            import torchvision.transforms.functional as F\n",
        "            transforms_module.functional_tensor = F\n",
        "            print(\"‚úì Fixed torchvision compatibility (shim)\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö† Torchvision fix warning: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Download only required models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4.5: Fix torchvision compatibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix torchvision compatibility: functional_tensor was moved in newer versions\n",
        "# Patch basicsr file directly since inference.py runs in subprocess\n",
        "import os\n",
        "import site\n",
        "\n",
        "# Find basicsr installation\n",
        "basicsr_path = None\n",
        "for path in site.getsitepackages():\n",
        "    degradations_file = os.path.join(path, \"basicsr\", \"data\", \"degradations.py\")\n",
        "    if os.path.exists(degradations_file):\n",
        "        basicsr_path = degradations_file\n",
        "        break\n",
        "\n",
        "# Also check common Colab paths\n",
        "if not basicsr_path:\n",
        "    common_paths = [\n",
        "        \"/usr/local/lib/python3.12/dist-packages/basicsr/data/degradations.py\",\n",
        "        \"/usr/local/lib/python3.11/dist-packages/basicsr/data/degradations.py\",\n",
        "        \"/usr/local/lib/python3.10/dist-packages/basicsr/data/degradations.py\",\n",
        "    ]\n",
        "    for p in common_paths:\n",
        "        if os.path.exists(p):\n",
        "            basicsr_path = p\n",
        "            break\n",
        "\n",
        "if basicsr_path:\n",
        "    with open(basicsr_path, \"r\") as f:\n",
        "        content = f.read()\n",
        "    \n",
        "    # Replace the problematic import\n",
        "    old_import = \"from torchvision.transforms.functional_tensor import rgb_to_grayscale\"\n",
        "    new_import = \"from torchvision.transforms.functional import rgb_to_grayscale\"\n",
        "    \n",
        "    if old_import in content and new_import not in content:\n",
        "        content = content.replace(old_import, new_import)\n",
        "        with open(basicsr_path, \"w\") as f:\n",
        "            f.write(content)\n",
        "        print(f\"‚úì Fixed torchvision compatibility in {basicsr_path}\")\n",
        "    elif new_import in content:\n",
        "        print(\"‚úì Torchvision compatibility already fixed\")\n",
        "    else:\n",
        "        print(f\"‚ö† Import line not found in {basicsr_path}\")\n",
        "else:\n",
        "    print(\"‚ö† Could not find basicsr/degradations.py - trying alternative fix...\")\n",
        "    # Alternative: monkey-patch at import time\n",
        "    import sys\n",
        "    import importlib.util\n",
        "    \n",
        "    def patch_torchvision():\n",
        "        import torchvision.transforms as transforms_module\n",
        "        if not hasattr(transforms_module, 'functional_tensor'):\n",
        "            from torchvision.transforms import functional as functional_tensor\n",
        "            transforms_module.functional_tensor = functional_tensor\n",
        "    \n",
        "    # This will be applied when basicsr imports\n",
        "    sys.modules['torchvision.transforms.functional_tensor'] = None\n",
        "    patch_torchvision()\n",
        "    print(\"‚úì Applied runtime patch (may need to restart kernel)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "CHECKPOINT_DIR = os.path.join(BASE_DIR, \"checkpoints\")\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# Download safetensor models (newer, simpler - just one file per size)\n",
        "print(\"Downloading SadTalker models (safetensor format)...\")\n",
        "models = [\n",
        "    (\"https://github.com/OpenTalker/SadTalker/releases/download/v0.0.2-rc/SadTalker_V0.0.2_256.safetensors\", \"SadTalker_V0.0.2_256.safetensors\"),\n",
        "    (\"https://github.com/OpenTalker/SadTalker/releases/download/v0.0.2-rc/mapping_00109-model.pth.tar\", \"mapping_00109-model.pth.tar\"),  # For 'full' preprocess\n",
        "]\n",
        "\n",
        "for url, filename in models:\n",
        "    filepath = os.path.join(CHECKPOINT_DIR, filename)\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"  Downloading {filename}...\")\n",
        "        urllib.request.urlretrieve(url, filepath)\n",
        "        print(f\"  ‚úì {filename}\")\n",
        "    else:\n",
        "        print(f\"  ‚úì {filename} (already exists)\")\n",
        "\n",
        "# Download GFPGAN weights for enhancer\n",
        "GFPGAN_DIR = os.path.join(BASE_DIR, \"gfpgan\", \"weights\")\n",
        "os.makedirs(GFPGAN_DIR, exist_ok=True)\n",
        "\n",
        "print(\"\\nDownloading GFPGAN enhancer weights...\")\n",
        "gfpgan_models = [\n",
        "    (\"https://github.com/xinntao/facexlib/releases/download/v0.1.0/alignment_WFLW_4HG.pth\", \"alignment_WFLW_4HG.pth\"),\n",
        "    (\"https://github.com/xinntao/facexlib/releases/download/v0.1.0/detection_Resnet50_Final.pth\", \"detection_Resnet50_Final.pth\"),\n",
        "    (\"https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth\", \"GFPGANv1.4.pth\"),\n",
        "    (\"https://github.com/xinntao/facexlib/releases/download/v0.2.2/parsing_parsenet.pth\", \"parsing_parsenet.pth\"),\n",
        "]\n",
        "\n",
        "for url, filename in gfpgan_models:\n",
        "    filepath = os.path.join(GFPGAN_DIR, filename)\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"  Downloading {filename}...\")\n",
        "        urllib.request.urlretrieve(url, filepath)\n",
        "        print(f\"  ‚úì {filename}\")\n",
        "    else:\n",
        "        print(f\"  ‚úì {filename} (already exists)\")\n",
        "\n",
        "print(\"\\n‚úì All models downloaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Gradio UI ‚Äî upload image + audio ‚Üí talking video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "import gradio as gr\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Fix numpy 2.x compatibility: np.float was removed\n",
        "if not hasattr(np, 'float'):\n",
        "    np.float = float\n",
        "if not hasattr(np, 'int'):\n",
        "    np.int = int\n",
        "if not hasattr(np, 'complex'):\n",
        "    np.complex = complex\n",
        "if not hasattr(np, 'bool'):\n",
        "    np.bool = bool\n",
        "\n",
        "BASE_DIR = \"/content/SadTalker\"\n",
        "CHECKPOINT_DIR = os.path.join(BASE_DIR, \"checkpoints\")\n",
        "os.chdir(BASE_DIR)\n",
        "sys.path.insert(0, BASE_DIR)\n",
        "\n",
        "RESULT_DIR = os.path.join(BASE_DIR, \"results\")\n",
        "os.makedirs(RESULT_DIR, exist_ok=True)\n",
        "\n",
        "# Lazy-load face detection (same as SadTalker uses)\n",
        "_face_preprocessor = None\n",
        "\n",
        "def get_face_preprocessor():\n",
        "    \"\"\"Lazy-load face detection preprocessor.\"\"\"\n",
        "    global _face_preprocessor\n",
        "    if _face_preprocessor is None:\n",
        "        try:\n",
        "            from src.utils.croper import Preprocesser\n",
        "            import torch\n",
        "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "            _face_preprocessor = Preprocesser(device=device)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö† Face detection init warning: {e}\")\n",
        "    return _face_preprocessor\n",
        "\n",
        "\n",
        "def validate_face_detection(image_path: str) -> tuple[bool, str]:\n",
        "    \"\"\"Validate face detection using SadTalker's method. Returns (success, message).\"\"\"\n",
        "    preprocessor = get_face_preprocessor()\n",
        "    if preprocessor is None:\n",
        "        return True, \"\"  # Skip validation if not initialized\n",
        "    \n",
        "    try:\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            return False, \"Could not read image file.\"\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Use same method as SadTalker: get_landmark() with detect_faces()\n",
        "        lm = preprocessor.get_landmark(img_rgb)\n",
        "        \n",
        "        if lm is None:\n",
        "            return False, \"‚ùå No face detected. Use a clear front-facing face image.\"\n",
        "        \n",
        "        return True, f\"‚úì Face detected (68 landmarks found)\"\n",
        "    except Exception as e:\n",
        "        return False, f\"Face detection error: {str(e)}\"\n",
        "\n",
        "\n",
        "def run_sadtalker(image_path: str, audio_path: str, result_dir: str) -> str:\n",
        "    \"\"\"Run SadTalker inference. Returns path to generated MP4.\"\"\"\n",
        "    cmd = [\n",
        "        sys.executable, \"inference.py\",\n",
        "        \"--driven_audio\", audio_path,\n",
        "        \"--source_image\", image_path,\n",
        "        \"--result_dir\", result_dir,\n",
        "        \"--checkpoint_dir\", CHECKPOINT_DIR,\n",
        "        \"--still\", \"--preprocess\", \"full\", \"--enhancer\", \"gfpgan\"\n",
        "    ]\n",
        "    env = os.environ.copy()\n",
        "    env[\"PYTHONPATH\"] = BASE_DIR\n",
        "    r = subprocess.run(cmd, cwd=BASE_DIR, env=env, capture_output=True, text=True)\n",
        "    if r.returncode != 0:\n",
        "        err = (r.stderr or \"\").strip() or (r.stdout or \"\").strip()\n",
        "        raise RuntimeError(f\"inference.py failed:\\n{err}\")\n",
        "    mp4s = sorted(Path(result_dir).rglob(\"*.mp4\"), key=os.path.getmtime, reverse=True)\n",
        "    if not mp4s:\n",
        "        raise FileNotFoundError(\"No output video found.\")\n",
        "    return str(mp4s[0])\n",
        "\n",
        "\n",
        "def _to_path(x):\n",
        "    if x is None: return None\n",
        "    if isinstance(x, str): return x\n",
        "    if hasattr(x, \"name\"): return x.name\n",
        "    return x.get(\"path\") or x.get(\"name\")\n",
        "\n",
        "\n",
        "def generate_video(image, audio):\n",
        "    if image is None:\n",
        "        return None, \"Please upload a face image.\"\n",
        "    if audio is None:\n",
        "        return None, \"Please upload an audio file (base sound).\"\n",
        "    image_path = _to_path(image)\n",
        "    audio_path = _to_path(audio)\n",
        "    if not image_path or not os.path.isfile(image_path):\n",
        "        return None, \"Invalid image file.\"\n",
        "    if not audio_path or not os.path.isfile(audio_path):\n",
        "        return None, \"Invalid audio file.\"\n",
        "    \n",
        "    # Validate face detection (same method as SadTalker inference uses)\n",
        "    face_ok, face_msg = validate_face_detection(image_path)\n",
        "    if not face_ok:\n",
        "        return None, face_msg\n",
        "    \n",
        "    try:\n",
        "        video_path = run_sadtalker(image_path, audio_path, RESULT_DIR)\n",
        "        return video_path, f\"‚úì Done: {os.path.basename(video_path)}\"\n",
        "    except Exception as e:\n",
        "        err_msg = str(e)\n",
        "        # Check if error is related to face detection\n",
        "        if \"Can't get the coeffs\" in err_msg or \"No face is detected\" in err_msg or \"landmark\" in err_msg.lower():\n",
        "            return None, f\"‚ùå Face detection failed: {err_msg}\\n\\nTip: Use a clear front-facing face image.\"\n",
        "        return None, f\"Error: {err_msg}\"\n",
        "\n",
        "\n",
        "with gr.Blocks(title=\"SadTalker ‚Äî Minimal\") as demo:\n",
        "    gr.Markdown(\"## Upload **image** + **audio** (base sound) ‚Üí talking video\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            image_in = gr.Image(type=\"filepath\", label=\"Face image\", sources=[\"upload\"])\n",
        "            audio_in = gr.Audio(type=\"filepath\", label=\"Base sound (audio)\", sources=[\"upload\"])\n",
        "            btn = gr.Button(\"Generate video\", variant=\"primary\")\n",
        "        with gr.Column():\n",
        "            video_out = gr.Video(label=\"Output video\")\n",
        "            status = gr.Textbox(label=\"Status\", interactive=False)\n",
        "    btn.click(\n",
        "        fn=generate_video,\n",
        "        inputs=[image_in, audio_in],\n",
        "        outputs=[video_out, status]\n",
        "    )\n",
        "\n",
        "# In Colab, launch with share=True and server_name so the UI is accessible\n",
        "demo.launch(share=True, server_name=\"0.0.0.0\", server_port=7860)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
